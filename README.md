# 🛸 수상한 배틀크루져 (Suspicious Battlecruiser)

‘수상한 배틀크루져’는 스타크래프트 세계관 속 등장인물들이 감염된 테란을 찾아내는 **우주선판 마피아 게임**입니다. LLM을 활용한 심리전과 추리가 결합된 싱글플레이 추리 시뮬레이션이며, 유저 1명과 LLM [AI]캐릭터 8명이 게임을 진행합니다.
<div align="center">
  <img src="https://image.librewiki.net/1/16/Battlecruiser_SCR_Art1.jpg" width="800" height="400"/>
</div>



## 🎮 게임 개요

- 배틀크루져 내부에서 저그로 부터 감염된 테란이 선량한 테란들 사이에 숨어 있습니다.
- 각 인물은 LLM 기반의 성격과 말투, 감정 상태, 추리 논리를 가지고 발언합니다.
- 플레이어는 각자의 대화, 단서, 감정 흐름을 기반으로 감염자를 추리해 매일 한 명을 우주 밖으로 추방하게 됩니다.
- 플레이어의 선택에 따라 테란이 승리하거나, 감염자가 최종 생존하여 저그가 승리하게 됩니다.

## 🧑‍🚀 등장인물 (총 8명)

| 짐 레이너 | 사라 케리건 | 사미르 듀란 | 에드먼드 듀크 | 아크튜러스 맹스크 | 톰 카잔스키 | 노바 테라 | 알렉세이 스투코프 |
|:---------:|:-----------:|:------------:|:--------------:|:-----------------:|:-------------:|:----------:|:-------------------:|
| <img src="data/raynor.jpg" width="1500" height="150"/> | <img src="data/kerrigan.jpg" width="1500" height="150"/> | <img src="data/duran.png" width="1500" height="150"/> | <img src="data/duke.jpg" width="1500" height="150"/> | <img src="data/mengsk.jpg" width="1500" height="150"/> | <img src="data/tom.jpg" width="1500" height="150"/> | <img src="data/nova.jpg" width="1500" height="150"/> | <img src="data/stukov.jpg" width="1500" height="150"/> |


## ⚙️ 설치 및 실행 환경

- **Python**: 3.9 이상
- **LLM**: Ollama 설치 후 `EEVE-Korean-10.8B` 실행 필요
- **권장 실행 환경**: 터미널 또는 VS Code

```bash
pip install ollama
ollama run EEVE-Korean-10.8B
```



## 💻:게임 로직
1. 초기화 및 역할 부여
2. Day1 자기소개 → 몰입 유도
3. 매일 단서 랜덤으로 자동 생성 + 진술 + 투표
4. 의심 점수 누적 및 감정 변화 반영
5. 추방 및 승패 판단
6. 게임 종료 후 분석 리포

## 🧠 LLM 기반 캐릭터 시스템

### 🎭 페르소나 주입 (Persona Prompting)

각 인물은 고유의 말투와 성격을 가집니다.  
본 게임은 **LLM(EEVE-Korean-10.8B)**에게 캐릭터의 페르소나를 명확히 전달하여, 인물 간의 말투와 사고방식을 차별화합니다.

| 인물 | 페르소나 설명 |
|------|---------------|
| 아크튜러스 멩스크 | 고상하고 독재자다운 말투, 대중 선동적, 권위적 표현 사용 |
| 짐 레이너 | 자유를 중시하는 보안관, 냉소적이면서도 인간적인 발언 |
| 사라 케리건 | 침착하고 단호한 유령 요원, 감정을 억누르는 말투 |
| 사미르 듀란 | 이중적인 전략가, 교묘하고 조심스러운 화법 |
| 에드먼드 듀크 | 원칙주의 장군, 분석적이고 냉정한 언행 |
| 톰 카잔스키 | 투박하고 직설적인 실전파 |
| 노바 테라 | 감정을 배제한 냉정한 요원, 간결하고 정확한 문장 |
| 알렉세이 스투코프 | 명예로운 해군 전략가, 고풍스럽고 품위 있는 말투 |

🧪 페르소나는 **발언 생성 시 LLM 프롬프트에 직접 삽입**되어, 캐릭터 간 개성 있는 심리전과 발언 흐름을 만듭니다.

---

### 💢 감정 상태 시뮬레이션 (Emotion Injection)

게임 중 캐릭터는 특정 감정 상태로 변화합니다.  
이는 **의심 점수**와 **동료의 추방 여부**에 따라 자동으로 반영됩니다.

| 감정 상태 | 트리거 조건 | 예시 프롬프트 |
|-----------|--------------|----------------|
| 기본 | 초기 상태 | (감정 설명 없음) |
| 불안 | 의심 점수 ≥ 2 | "당신은 최근 의심을 받아 불안한 상태입니다." |
| 슬픔 | 동료가 추방됨 | "당신은 동료의 추방으로 슬픔에 잠겨 있습니다." |
| 분노 | 감염자가 추방됨 | "당신은 누군가에게 강한 분노를 느끼고 있습니다." |
| 체념 | 반복 의심/무기력 | "당신은 체념한 상태로 무기력하게 말합니다." |

💬 이 감정 설명은 LLM 프롬프트에 **보조 입력**으로 삽입되며,  
캐릭터의 대사에 감정적 뉘앙스를 더해 플레이어가 심리 상태를 추리할 수 있게 합니다.

---

### 🔍 의심 점수 시스템 (Suspicion Score System)

게임에서는 각 캐릭터의 발언이 **반복되거나 비정상적일 경우**, 내부적으로 "의심 점수(Suspicion Score)"가 올라갑니다.  
이는 LLM이 직접 판단하는 것이 아니라, 게임 로직에서 조건에 따라 **자동 계산되는 수치 기반 로직**입니다.

---

#### 📌 작동 방식

```python
if memory in memory_log[pid]:  # 이전에 했던 기억과 동일한 진술이라면
    suspicion_score[pid] += 1  # 의심 점수 +1
```
- memory_log: 각 캐릭터가 과거에 했던 발언(기억)을 저장하는 구조

- suspicion_score: 반복 발언 시 자동 증가되는 수치

- 점수는 누적되며, 감정 상태(emotion_state) 변경에 활용됩니다

- ⚠️ LLM은 점수를 계산하지 않으며, 게임 로직이 점수를 계산 → 결과만 LLM에게 전달
---

### 🧩 AI 추론 시스템 구조

본 게임은 아래와 같은 구조로 LLM 추론을 구성합니다:

1. **페르소나**: 캐릭터 성격과 말투 주입
2. **감정 상태**: 불안/분노/슬픔 등 상황 기반 감정 주입
3. **기억 단서**: 매일 자동 생성된 목격/기억 정보
4. **기억 누적 & 반복 체크**: 같은 발언 반복 시 의심 수치 상승
5. **비밀 메시지**: 일부 캐릭터가 플레이어에게만 은밀하게 정보 전달

🧠 위 요소를 모두 조합하여, LLM은 매일 **심리적으로 설득력 있는 발언**을 생성합니다.

---

### 🎮 추리의 재미 요소

- 페르소나 기반 말투 차이로 심리 추론 가능  
- 감정 변화 흐름 추적으로 감염자 가능성 분석  
- 플레이어만 볼 수 있는 은밀한 비밀 메시지 시스템  
- 반복되는 대사 탐지로 수상한 인물 추려내기  
- 몰입도 높은 스토리 프롬프트로 시작되는 시나리오 기반 게임 진행

---

> 🛸 **수상한 배틀크루져**는 단순한 마피아 게임이 아닙니다.  
> LLM을 활용해 각 인물이 **진짜처럼 말하고**, **심리 상태를 표현하며**,  
> 여러분은 그 대사를 근거로 **정교한 추리**를 펼쳐야 합니다.

---

### ⏭️: Conclusion & Limitation
라마 모델이 성능이 gpt에 비해 월등히 떨어지기 때문에, HuggingFace에서 제공하는 모델 튜닝 라이브러리로 TRL(Transformer Reinforcement Learning)이 있는데, 이는 다시 정리하면, Transformer 언어 모델을 학습하기 위한 라이브러리로, LLM 파인튜닝을 하기 위해 TRL 라이브러리의 Trainer 클래스 또는 SFTTrainer 클래스를 이용해야 합니다.

> Trainer 사용: 데이터 세트가 크고 학습 loop 또는 복잡한 학습 워크플로우에 대한 광범위한 사용자 정의가 필요한 경우.
> SFTTrainer 사용: 사전 학습된 모델과 상대적으로 작은 데이터셋이 있고 효율적인 메모리 사용으로 더 간단하고 빠른 파인튜닝을 원하는 경우.

하지만 이 작업을 진행하려면 (예:배달의 민족 QA) 정재한 데이터 필요.

또한 한글 같은경우 성능을 끌어올리기 위해 파인튜닝이 필수적.
하지만 이를 해결 하고자 파인튜닝 보다는 커스터마이징에 가까운 페르소나, 캐릭터 프롬프트, 스토리 프롬프트 주입.

Reference: https://velog.io/@judy_choi/LLMLLaMA3-Fine-Tuning-방법-정리

